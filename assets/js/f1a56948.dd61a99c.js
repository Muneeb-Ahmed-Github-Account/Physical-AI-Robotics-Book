"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[1865],{8012:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"ros2/applications","title":"ROS 2 Applications","description":"Real-world applications and use cases of ROS 2 in humanoid robotics","source":"@site/docs/ros2/applications.md","sourceDirName":"ros2","slug":"/ros2/applications","permalink":"/Physical-AI-Robotics-Book/docs/ros2/applications","draft":false,"unlisted":false,"editUrl":"https://github.com/Muneeb-Ahmed-Github-Account/Physical-AI-Robotics-Book/tree/main/docs/ros2/applications.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"ROS 2 Applications","sidebar_position":5,"description":"Real-world applications and use cases of ROS 2 in humanoid robotics"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Examples","permalink":"/Physical-AI-Robotics-Book/docs/ros2/examples"},"next":{"title":"ROS 2 Exercises","permalink":"/Physical-AI-Robotics-Book/docs/ros2/exercises"}}');var t=n(4848),a=n(8453);const s={title:"ROS 2 Applications",sidebar_position:5,description:"Real-world applications and use cases of ROS 2 in humanoid robotics"},r="ROS 2 Applications",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Industrial Applications",id:"industrial-applications",level:2},{value:"Manufacturing and Assembly",id:"manufacturing-and-assembly",level:3},{value:"Warehouse and Logistics",id:"warehouse-and-logistics",level:3},{value:"Research and Development",id:"research-and-development",level:2},{value:"Academic Research",id:"academic-research",level:3},{value:"Open Source Humanoid Projects",id:"open-source-humanoid-projects",level:3},{value:"Healthcare and Assistive Robotics",id:"healthcare-and-assistive-robotics",level:2},{value:"Rehabilitation Robots",id:"rehabilitation-robots",level:3},{value:"Surgical Assistants",id:"surgical-assistants",level:3},{value:"Service Robotics",id:"service-robotics",level:2},{value:"Customer Service Robots",id:"customer-service-robots",level:3},{value:"Educational Robots",id:"educational-robots",level:3},{value:"Autonomous Systems Integration",id:"autonomous-systems-integration",level:2},{value:"Multi-Robot Coordination",id:"multi-robot-coordination",level:3},{value:"Heterogeneous Robot Teams",id:"heterogeneous-robot-teams",level:3},{value:"Perception and AI Integration",id:"perception-and-ai-integration",level:2},{value:"Computer Vision",id:"computer-vision",level:3},{value:"Machine Learning Integration",id:"machine-learning-integration",level:3},{value:"Navigation and Mapping",id:"navigation-and-mapping",level:2},{value:"SLAM (Simultaneous Localization and Mapping)",id:"slam-simultaneous-localization-and-mapping",level:3},{value:"Path Planning and Trajectory Generation",id:"path-planning-and-trajectory-generation",level:3},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:2},{value:"Natural Language Processing",id:"natural-language-processing",level:3},{value:"Gesture Recognition",id:"gesture-recognition",level:3},{value:"Safety and Certification",id:"safety-and-certification",level:2},{value:"Safety-Critical Applications",id:"safety-critical-applications",level:3},{value:"Fault Tolerance",id:"fault-tolerance",level:3},{value:"Simulation and Testing",id:"simulation-and-testing",level:2},{value:"Gazebo Integration",id:"gazebo-integration",level:3},{value:"Hardware-in-the-Loop Testing",id:"hardware-in-the-loop-testing",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Real-time Control",id:"real-time-control",level:3},{value:"Resource Management",id:"resource-management",level:3},{value:"Future Applications",id:"future-applications",level:2},{value:"Cloud Robotics",id:"cloud-robotics",level:3},{value:"5G Integration",id:"5g-integration",level:3},{value:"Edge Computing",id:"edge-computing",level:3},{value:"Best Practices from Real Applications",id:"best-practices-from-real-applications",level:2},{value:"Modularity and Reusability",id:"modularity-and-reusability",level:3},{value:"Performance Monitoring",id:"performance-monitoring",level:3},{value:"Security Implementation",id:"security-implementation",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:3},{value:"Challenges and Solutions",id:"challenges-and-solutions",level:2},{value:"Network Latency",id:"network-latency",level:3},{value:"Computational Constraints",id:"computational-constraints",level:3},{value:"Integration Complexity",id:"integration-complexity",level:3},{value:"Cross-References",id:"cross-references",level:2},{value:"References",id:"references",level:2}];function d(e){const i={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"ros-2-applications",children:"ROS 2 Applications"})}),"\n",(0,t.jsx)(i.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(i.p,{children:"After completing this section, students will be able to:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Identify real-world applications of ROS 2 in humanoid robotics"}),"\n",(0,t.jsx)(i.li,{children:"Understand how ROS 2 is used in industrial, healthcare, and service robotics"}),"\n",(0,t.jsx)(i.li,{children:"Recognize the integration of ROS 2 with perception and AI systems"}),"\n",(0,t.jsx)(i.li,{children:"Describe the role of ROS 2 in navigation and mapping for humanoid robots"}),"\n",(0,t.jsx)(i.li,{children:"Explain human-robot interaction patterns in ROS 2-based systems"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 has become the de facto standard for robotics development, with numerous real-world applications across various domains. In humanoid robotics specifically, ROS 2 provides the necessary infrastructure for complex systems that require coordination between multiple subsystems, real-time control, and integration with AI systems."}),"\n",(0,t.jsx)(i.h2,{id:"industrial-applications",children:"Industrial Applications"}),"\n",(0,t.jsx)(i.h3,{id:"manufacturing-and-assembly",children:"Manufacturing and Assembly"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 is extensively used in industrial humanoid robotics for tasks such as assembly, quality inspection, and material handling. The middleware's real-time capabilities and deterministic communication make it suitable for applications where timing is critical and human workers collaborate with robots."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: ABB YuMi"}),"\nThe ABB YuMi collaborative robot uses ROS-based architecture for dual-arm manipulation tasks. The system coordinates multiple sensors, actuators, and vision systems to perform precise assembly operations alongside human workers [1]."]}),"\n",(0,t.jsx)(i.h3,{id:"warehouse-and-logistics",children:"Warehouse and Logistics"}),"\n",(0,t.jsx)(i.p,{children:"Humanoid robots in warehouse environments use ROS 2 for navigation, object recognition, and manipulation tasks. The distributed architecture allows these robots to operate in dynamic environments while maintaining communication with central systems."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Amazon Robotics"}),"\nAmazon's robotic systems use ROS-based architectures for package handling and sorting in fulfillment centers. The robots navigate complex environments, identify objects, and manipulate items with precision [2]."]}),"\n",(0,t.jsx)(i.h2,{id:"research-and-development",children:"Research and Development"}),"\n",(0,t.jsx)(i.h3,{id:"academic-research",children:"Academic Research"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 is the backbone of numerous humanoid robotics research projects worldwide. Its modular architecture and extensive package ecosystem make it ideal for rapid prototyping and experimentation."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Boston Dynamics Atlas"}),"\nWhile Boston Dynamics primarily uses proprietary systems, research teams worldwide have developed ROS 2 interfaces for humanoid robots inspired by the Atlas platform. These interfaces enable researchers to experiment with perception, planning, and control algorithms [3]."]}),"\n",(0,t.jsx)(i.h3,{id:"open-source-humanoid-projects",children:"Open Source Humanoid Projects"}),"\n",(0,t.jsx)(i.p,{children:"Several open-source humanoid robot projects rely on ROS 2 for development and deployment:"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: ROSIN Project"}),"\nThe ROSIN project developed ROS 2 interfaces for various industrial robots, including humanoid platforms. This project demonstrated how ROS 2 could be used to create reusable components for complex robotic systems [4]."]}),"\n",(0,t.jsx)(i.h2,{id:"healthcare-and-assistive-robotics",children:"Healthcare and Assistive Robotics"}),"\n",(0,t.jsx)(i.h3,{id:"rehabilitation-robots",children:"Rehabilitation Robots"}),"\n",(0,t.jsx)(i.p,{children:"Humanoid robots in healthcare settings use ROS 2 for precise control and safety-critical operations. The middleware's security features and real-time capabilities make it suitable for applications where human safety is paramount."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: RIBA (Robot for Interactive Body Assistance)"}),"\nThe RIBA robot developed by RIKEN and Sumitomo Riko uses ROS-based architecture for patient lifting and assistance. The system requires precise control and safety mechanisms that ROS 2's architecture supports [5]."]}),"\n",(0,t.jsx)(i.h3,{id:"surgical-assistants",children:"Surgical Assistants"}),"\n",(0,t.jsx)(i.p,{children:"Advanced surgical robots incorporate ROS 2 for coordination between multiple subsystems, including imaging, control, and safety monitoring. The middleware's reliability and deterministic communication are crucial for medical applications."}),"\n",(0,t.jsx)(i.h2,{id:"service-robotics",children:"Service Robotics"}),"\n",(0,t.jsx)(i.h3,{id:"customer-service-robots",children:"Customer Service Robots"}),"\n",(0,t.jsx)(i.p,{children:"Humanoid robots in service industries use ROS 2 for navigation, human-robot interaction, and task execution. The middleware's flexibility allows these robots to adapt to dynamic environments and user requests."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: SoftBank Pepper"}),"\nWhile Pepper uses a proprietary system, many research implementations of similar service robots use ROS 2 for speech recognition, navigation, and human-robot interaction [6]."]}),"\n",(0,t.jsx)(i.h3,{id:"educational-robots",children:"Educational Robots"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 is widely adopted in educational humanoid robots that help students learn programming, robotics, and AI concepts. The extensive documentation and community support make it ideal for educational settings."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: NAO Robot Educational Use"}),"\nMany universities use NAO robots with ROS 2 interfaces for teaching robotics, AI, and human-robot interaction concepts. The modular architecture allows students to experiment with different components [7]."]}),"\n",(0,t.jsx)(i.h2,{id:"autonomous-systems-integration",children:"Autonomous Systems Integration"}),"\n",(0,t.jsx)(i.h3,{id:"multi-robot-coordination",children:"Multi-Robot Coordination"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2's distributed architecture is ideal for coordinating multiple humanoid robots working together. The middleware's domain ID system allows for isolation of different robot teams while enabling communication when needed."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: RoboCup Humanoid League"}),"\nTeams in the RoboCup Humanoid League often use ROS 2 for their robots. The middleware enables coordination between multiple robots on the same team while maintaining communication with the referee system [8]."]}),"\n",(0,t.jsx)(i.h3,{id:"heterogeneous-robot-teams",children:"Heterogeneous Robot Teams"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 allows for integration of different types of robots (humanoid, wheeled, aerial) working together. The common message types and communication patterns make it easier to develop coordinated behaviors across different robot platforms."}),"\n",(0,t.jsx)(i.h2,{id:"perception-and-ai-integration",children:"Perception and AI Integration"}),"\n",(0,t.jsx)(i.h3,{id:"computer-vision",children:"Computer Vision"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 provides extensive support for computer vision applications in humanoid robots through packages like OpenCV integration, image transport, and camera drivers. This enables humanoid robots to perceive and understand their environment."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: OpenCV Integration"}),"\nHumanoid robots use ROS 2's image transport system to efficiently share camera data between perception nodes, enabling real-time object detection, tracking, and recognition [9]."]}),"\n",(0,t.jsx)(i.h3,{id:"machine-learning-integration",children:"Machine Learning Integration"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 integrates with machine learning frameworks like TensorFlow and PyTorch, enabling humanoid robots to incorporate AI capabilities for decision-making, learning, and adaptation."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: TensorFlow Integration"}),"\nHumanoid robots use ROS 2 nodes that interface with TensorFlow models for tasks like gesture recognition, speech processing, and behavior prediction [10]."]}),"\n",(0,t.jsx)(i.h2,{id:"navigation-and-mapping",children:"Navigation and Mapping"}),"\n",(0,t.jsx)(i.h3,{id:"slam-simultaneous-localization-and-mapping",children:"SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 provides robust SLAM capabilities that are essential for humanoid robots that need to navigate complex environments. The Navigation2 stack provides state-of-the-art navigation capabilities."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Navigation2 Stack"}),"\nThe Navigation2 stack in ROS 2 provides localization, path planning, and obstacle avoidance for mobile robots, including humanoid platforms that need to navigate spaces [11]."]}),"\n",(0,t.jsx)(i.h3,{id:"path-planning-and-trajectory-generation",children:"Path Planning and Trajectory Generation"}),"\n",(0,t.jsx)(i.p,{children:"Humanoid robots require sophisticated path planning that considers their complex kinematics and dynamics. ROS 2's planning scene representation and trajectory execution capabilities support these requirements."}),"\n",(0,t.jsx)(i.h2,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,t.jsx)(i.h3,{id:"natural-language-processing",children:"Natural Language Processing"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 enables integration of speech recognition and natural language processing systems that allow humanoid robots to communicate with humans using natural language."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Speech Recognition Nodes"}),"\nHumanoid robots use ROS 2 nodes that integrate with speech recognition APIs, enabling voice-based interaction and command processing [12]."]}),"\n",(0,t.jsx)(i.h3,{id:"gesture-recognition",children:"Gesture Recognition"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 supports integration of computer vision and machine learning systems for gesture recognition, allowing humanoid robots to interpret human gestures and respond appropriately."}),"\n",(0,t.jsx)(i.h2,{id:"safety-and-certification",children:"Safety and Certification"}),"\n",(0,t.jsx)(i.h3,{id:"safety-critical-applications",children:"Safety-Critical Applications"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2's real-time capabilities and deterministic behavior make it suitable for safety-critical applications in humanoid robotics. The middleware supports various safety protocols and standards."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: IEC 61508 Compliance"}),"\nROS 2 can be configured to meet safety standards like IEC 61508 for safety-related systems, making it suitable for humanoid robots in safety-critical environments [13]."]}),"\n",(0,t.jsx)(i.h3,{id:"fault-tolerance",children:"Fault Tolerance"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2's distributed architecture and Quality of Service (QoS) policies enable fault-tolerant systems that can continue operating even when individual components fail."}),"\n",(0,t.jsx)(i.h2,{id:"simulation-and-testing",children:"Simulation and Testing"}),"\n",(0,t.jsx)(i.h3,{id:"gazebo-integration",children:"Gazebo Integration"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 has excellent integration with Gazebo simulation, enabling comprehensive testing and validation of humanoid robot behaviors before deployment on real hardware."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Gazebo Harmonic"}),"\nThe latest Gazebo Harmonic provides native ROS 2 integration, enabling realistic simulation of humanoid robots with accurate physics and sensor models [14]."]}),"\n",(0,t.jsx)(i.h3,{id:"hardware-in-the-loop-testing",children:"Hardware-in-the-Loop Testing"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 supports hardware-in-the-loop testing where some components run on real hardware while others run in simulation, enabling safe testing of humanoid robot systems."}),"\n",(0,t.jsx)(i.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(i.h3,{id:"real-time-control",children:"Real-time Control"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2's real-time capabilities enable precise control of humanoid robot joints and actuators, which is essential for stable locomotion and manipulation."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Example: Real-time Kernel Integration"}),"\nROS 2 can be used with real-time kernels to ensure deterministic behavior for critical control loops in humanoid robots [15]."]}),"\n",(0,t.jsx)(i.h3,{id:"resource-management",children:"Resource Management"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 provides tools for monitoring and managing computational resources, which is important for humanoid robots with limited computational capacity."}),"\n",(0,t.jsx)(i.h2,{id:"future-applications",children:"Future Applications"}),"\n",(0,t.jsx)(i.h3,{id:"cloud-robotics",children:"Cloud Robotics"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 supports cloud robotics applications where humanoid robots offload computation to cloud services, enabling more sophisticated AI capabilities without increasing local computational requirements."}),"\n",(0,t.jsx)(i.h3,{id:"5g-integration",children:"5G Integration"}),"\n",(0,t.jsx)(i.p,{children:"With the advent of 5G networks, ROS 2 enables humanoid robots to leverage low-latency, high-bandwidth communication for remote operation and coordination."}),"\n",(0,t.jsx)(i.h3,{id:"edge-computing",children:"Edge Computing"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2 nodes can be deployed on edge computing devices, bringing AI capabilities closer to humanoid robots while maintaining low latency and privacy."}),"\n",(0,t.jsx)(i.h2,{id:"best-practices-from-real-applications",children:"Best Practices from Real Applications"}),"\n",(0,t.jsx)(i.h3,{id:"modularity-and-reusability",children:"Modularity and Reusability"}),"\n",(0,t.jsx)(i.p,{children:"Successful ROS 2 applications in humanoid robotics emphasize modularity, with well-defined interfaces between components that can be reused across different robot platforms."}),"\n",(0,t.jsx)(i.h3,{id:"performance-monitoring",children:"Performance Monitoring"}),"\n",(0,t.jsx)(i.p,{children:"Real-world applications implement comprehensive monitoring and logging to track system performance and identify bottlenecks in complex humanoid robot systems."}),"\n",(0,t.jsx)(i.h3,{id:"security-implementation",children:"Security Implementation"}),"\n",(0,t.jsx)(i.p,{children:"Production humanoid robots using ROS 2 implement security measures including authentication, encryption, and access control to protect against cyber threats."}),"\n",(0,t.jsx)(i.h3,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,t.jsx)(i.p,{children:"Successful applications include extensive testing frameworks that validate both individual components and integrated systems before deployment."}),"\n",(0,t.jsx)(i.h2,{id:"challenges-and-solutions",children:"Challenges and Solutions"}),"\n",(0,t.jsx)(i.h3,{id:"network-latency",children:"Network Latency"}),"\n",(0,t.jsx)(i.p,{children:"In distributed humanoid robot systems, ROS 2's Quality of Service (QoS) policies help manage network latency and ensure critical messages are delivered with appropriate priority."}),"\n",(0,t.jsx)(i.h3,{id:"computational-constraints",children:"Computational Constraints"}),"\n",(0,t.jsx)(i.p,{children:"Humanoid robots often have limited computational resources. ROS 2's efficient message passing and node management help optimize resource usage."}),"\n",(0,t.jsx)(i.h3,{id:"integration-complexity",children:"Integration Complexity"}),"\n",(0,t.jsx)(i.p,{children:"ROS 2's extensive package ecosystem and standard interfaces help manage the complexity of integrating multiple subsystems in humanoid robots."}),"\n",(0,t.jsx)(i.h2,{id:"cross-references",children:"Cross-References"}),"\n",(0,t.jsx)(i.p,{children:"For related concepts, see:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"/Physical-AI-Robotics-Book/docs/digital-twin/advanced-sim",children:"Digital Twin Simulation"})," for simulation applications in humanoid robotics"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"/Physical-AI-Robotics-Book/docs/nvidia-isaac/best-practices",children:"NVIDIA Isaac"})," for best practices in advanced robotics applications"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"/Physical-AI-Robotics-Book/docs/vla-systems/applications",children:"Vision-Language-Action Systems"})," for AI system applications"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"/Physical-AI-Robotics-Book/docs/capstone-humanoid/project-outline",children:"Capstone Humanoid Project"})," for complete project applications"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(i.p,{children:['[1] ABB Robotics. (2023). "YuMi Collaborative Robot". Retrieved from ',(0,t.jsx)(i.a,{href:"https://new.abb.com/products/robotics/connected-robotics/yumi",children:"https://new.abb.com/products/robotics/connected-robotics/yumi"})]}),"\n",(0,t.jsxs)(i.p,{children:['[2] Amazon Robotics. (2023). "Amazon Robotics Solutions". Retrieved from ',(0,t.jsx)(i.a,{href:"https://www.aboutamazon.com/workplace/amazon-robotics",children:"https://www.aboutamazon.com/workplace/amazon-robotics"})]}),"\n",(0,t.jsxs)(i.p,{children:['[3] Boston Dynamics. (2023). "Atlas Robot". Retrieved from ',(0,t.jsx)(i.a,{href:"https://www.bostondynamics.com/products/atlas",children:"https://www.bostondynamics.com/products/atlas"})]}),"\n",(0,t.jsxs)(i.p,{children:['[4] ROSIN Project. (2023). "ROS-Industrial Consortium". Retrieved from ',(0,t.jsx)(i.a,{href:"https://rosin-project.eu/",children:"https://rosin-project.eu/"})]}),"\n",(0,t.jsxs)(i.p,{children:['[5] RIKEN. (2023). "RIBA Robot". Retrieved from ',(0,t.jsx)(i.a,{href:"https://www.riken.jp/en/research/labs/riken_bu/comp_intelligence/",children:"https://www.riken.jp/en/research/labs/riken_bu/comp_intelligence/"})]}),"\n",(0,t.jsxs)(i.p,{children:['[6] SoftBank Robotics. (2023). "Pepper Robot". Retrieved from ',(0,t.jsx)(i.a,{href:"https://www.softbankrobotics.com/emea/en/pepper",children:"https://www.softbankrobotics.com/emea/en/pepper"})]}),"\n",(0,t.jsxs)(i.p,{children:['[7] SoftBank Robotics. (2023). "NAO Robot Educational Use". Retrieved from ',(0,t.jsx)(i.a,{href:"https://www.ald.softbankrobotics.com/en/cool-robots/nao",children:"https://www.ald.softbankrobotics.com/en/cool-robots/nao"})]}),"\n",(0,t.jsxs)(i.p,{children:['[8] RoboCup Federation. (2023). "Humanoid League". Retrieved from ',(0,t.jsx)(i.a,{href:"https://humanoid.robocup.org/",children:"https://humanoid.robocup.org/"})]}),"\n",(0,t.jsxs)(i.p,{children:['[9] OpenCV. (2023). "OpenCV with ROS 2". Retrieved from ',(0,t.jsx)(i.a,{href:"https://github.com/ros-perception/vision_opencv",children:"https://github.com/ros-perception/vision_opencv"})]}),"\n",(0,t.jsxs)(i.p,{children:['[10] TensorFlow. (2023). "TensorFlow with ROS 2". Retrieved from ',(0,t.jsx)(i.a,{href:"https://github.com/tensorflow/ros_tensorflow",children:"https://github.com/tensorflow/ros_tensorflow"})]}),"\n",(0,t.jsxs)(i.p,{children:['[11] Navigation2. (2023). "Navigation System for ROS 2". Retrieved from ',(0,t.jsx)(i.a,{href:"https://navigation.ros.org/",children:"https://navigation.ros.org/"})]}),"\n",(0,t.jsxs)(i.p,{children:['[12] Speech Recognition. (2023). "Speech Recognition in ROS 2". Retrieved from ',(0,t.jsx)(i.a,{href:"https://github.com/CMU-Robotics-Repository/speech_recognition",children:"https://github.com/CMU-Robotics-Repository/speech_recognition"})]}),"\n",(0,t.jsxs)(i.p,{children:['[13] IEC Standards. (2023). "IEC 61508 Functional Safety". Retrieved from ',(0,t.jsx)(i.a,{href:"https://webstore.iec.ch/publication/2265",children:"https://webstore.iec.ch/publication/2265"})]}),"\n",(0,t.jsxs)(i.p,{children:['[14] Gazebo. (2023). "Gazebo Harmonic". Retrieved from ',(0,t.jsx)(i.a,{href:"https://gazebosim.org/",children:"https://gazebosim.org/"})]}),"\n",(0,t.jsxs)(i.p,{children:['[15] ROS 2 Real-time. (2023). "Real-time Programming with ROS 2". Retrieved from ',(0,t.jsx)(i.a,{href:"https://docs.ros.org/en/rolling/Tutorials/Real-Time-Programming.html",children:"https://docs.ros.org/en/rolling/Tutorials/Real-Time-Programming.html"})]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>s,x:()=>r});var o=n(6540);const t={},a=o.createContext(t);function s(e){const i=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(a.Provider,{value:i},e.children)}}}]);